from common.utils import generate_cover_letter_pdf, load_json_file, write_json_file
from sentence_transformers import SentenceTransformer
from integrations.mail_handler import MailClient
from integrations.seek_client import SeekClient
from scipy.spatial.distance import cosine
from scrapers.scraper import JobScraper
from integrations.agent import AIAgent
from datetime import datetime
import logging
import time

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
)

class ApplicationPipeline:
    def __init__(self, run_config, args):
        self.scraper = JobScraper(run_config)
        self.args = args
        self.source = run_config.get("source", "seek")
        self.mode = run_config.get("mode", "apply")
        self.agent = None
        self.mail_client = MailClient(args.mail_protocol)
        self.applied = self._load_applied(args.applied_path)
        self.model = None
        self.encoded_resume_txt = None
        if self.source != "ufl":
            self.agent = AIAgent(args.first_name, args.model).agent
            self.model = SentenceTransformer('all-MiniLM-L6-v2')
            self.encoded_resume_txt = self.model.encode(self.args.resume_txt, convert_to_numpy=True)

    def _load_applied(self, path):
        applied = load_json_file(path)
        if not applied:
            return {'jobs': {}, 'email_history': {}}
        
        return applied

    def calculate_resume_jd_similarity(self, jd_text):
        if not self.model or not self.encoded_resume_txt:
            return 0.0
        jd_vector = self.model.encode(jd_text, convert_to_numpy=True)
        sim_score = 1 - cosine(self.encoded_resume_txt, jd_vector)

        return float(sim_score)

    def should_skip_email(self, email):
        if email in self.applied['email_history']:
            last_contacted = datetime.fromisoformat(self.applied['email_history'][email]['last_contacted'])
            days_since_contact = (datetime.now() - last_contacted).days
            if days_since_contact < 7:
                logging.info(f"Recently contacted {email} {days_since_contact} days ago, skipping.")    
                return True
        return False

    async def run(self):
        if self.source == "ufl":
            await self._run_ufl_notifications()
            return
        logging.info("Scraping job listings...")
        data = await self.scraper.scrape("websift/seek-job-scraper")
        with SeekClient(self.mail_client) as seek_client:
            for searchTerm, job_data in data.items():
                if not job_data:
                    logging.info(f'No jobs found for search term: {searchTerm}, exiting.')
                    continue
                logging.info(f"Found {len(job_data)} jobs for search term: {searchTerm}")

                for job in job_data:
                    try:
                        job_id = job['id']
                        logging.info(f"Processing job: {job_id}")
                        if job_id in self.applied['jobs']:
                            logging.info(f"Already applied to job {job_id}, skipping.")
                            continue
                        # Re init agent if using meta ai to avoid limit context window issues
                        if not self.args.use_openai:
                            self.agent = AIAgent(self.args.first_name).agent
                        
                        position = job.get('title', '')
                        raw_content = job.get('content', {})
                        job_description = raw_content.get('sections')
                        if not job_description:
                            logging.error("No job description found, unable to process job, skipping.")
                            continue
                        
                        score = self.calculate_resume_jd_similarity(" ".join(job_description))
                        if score < self.args.min_score:
                            logging.info(f"Low similarity score {score} for job {job_id}, skipping.")
                            continue
                        
                        seek_success = False
                        email_success = False
                        emails_contacted = []

                        cover_letter = self.agent.prepare_cover_letter(job, self.args.resume_txt, self.args.australian_language)
                        generate_cover_letter_pdf(cover_letter, self.args.cover_letter_path)

                        # Skip over jobs that require questions to be answered
                        if seek_client.is_logged_in and (not job['hasRoleRequirements'] and not job['isExternalApply']):
                            success = seek_client.apply(job_id, resume_path=self.args.resume_pdf_path, cover_letter_path=self.args.cover_letter_path, show_recent_role=self.args.show_recent_role)
                            if success:
                                logging.info(f"successfully applied to job {job_id} via seek")
                                seek_success = True

                            
                        for email in job['emails']:
                            if self.should_skip_email(email):
                                continue

                            msg = self.agent.write_email_contents()

                            success = self.mail_client.send_application(
                                email,
                                job,
                                msg,
                                self.args.resume_pdf_path,
                                self.args.cover_letter_path
                            )
                            if success:
                                email_success = True
                                emails_contacted.append(email)
                                if email in self.applied['email_history']:
                                    self.applied['email_history'][email]['last_contacted'] = datetime.now().isoformat()
                                    self.applied['email_history'][email]['jobs_contacted'].append(job_id)
                                else:
                                    self.applied['email_history'][email] = {
                                        'last_contacted': datetime.now().isoformat(),
                                        'jobs_contacted': [job_id]
                                    }
                        
                        self.applied['jobs'][job_id] = {
                            'applied_on': datetime.now().isoformat(),
                            'similarity_score': score,
                            'applied_via_seek': seek_success,
                            'applied_via_email': email_success,
                            'emails_contacted': emails_contacted,
                            'position': position,
                            'link': job.get('jobLink', '')
                        }

                        write_json_file(self.args.applied_path, self.applied)
                    except Exception as e:
                        logging.error(f"Error processing job application: {e}")

                    # Wait 30sec to not overload api can be removed if using official apis
                    if not self.args.use_openai:
                        logging.info('sleeping')
                        time.sleep(30)

    async def _run_ufl_notifications(self):
        logging.info("Scraping UF job listings...")
        jobs = await self.scraper.scrape()
        if not jobs:
            logging.info("No jobs found for UF listing, exiting.")
            return

        notification_email = self.args.notify_email
        if not notification_email:
            notification_email = self.mail_client.user_email

        for job in jobs:
            job_id = job.get("id")
            if not job_id:
                continue
            if job_id in self.applied["jobs"]:
                logging.info(f"Already notified for job {job_id}, skipping.")
                continue

            subject = f"New UF job opening: {job.get('title', 'Unknown role')}"
            body_lines = [
                f"Title: {job.get('title', 'Unknown')}",
                f"Job ID: {job_id}",
                f"Location: {job.get('location', 'Not listed')}",
                f"Category: {job.get('category', 'Not listed')}",
                f"Work type: {job.get('work_type', 'Not listed')}",
                f"Link: {job.get('jobLink', '')}",
            ]
            body = "\n".join(body_lines)

            success = self.mail_client.send_notification(notification_email, subject, body)
            if not success:
                logging.error(f"Failed to send notification for job {job_id}")
                continue

            self.applied["jobs"][job_id] = {
                "notified_on": datetime.now().isoformat(),
                "position": job.get("title", ""),
                "link": job.get("jobLink", ""),
                "source": "ufl",
            }
            write_json_file(self.args.applied_path, self.applied)
